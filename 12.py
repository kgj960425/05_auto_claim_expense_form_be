import pymupdf4llm
import fitz
import pytesseract
import cv2
import numpy as np
from PIL import Image
import re
import os

PDF_PATH = r"C:\Users\user\Desktop\expense_cliaim\1.pdf"
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

print("PyMuPDF4LLM + OCR Pipeline")
print(f"PDF: {PDF_PATH}")

# ë¨¼ì € PyMuPDFë¡œ í…ìŠ¤íŠ¸ê°€ ìˆëŠ”ì§€ í™•ì¸
doc = fitz.open(PDF_PATH)
print(f"\nTotal pages: {len(doc)}")

for page_num in range(len(doc)):
    page = doc[page_num]
    text = page.get_text()
    print(f"\nPage {page_num + 1} - Text length: {len(text)}")
    if text.strip():
        print(f"First 200 chars: {text[:200]}")
    else:
        print("âš ï¸ No text found - This is likely an image-based PDF")

doc.close()

# PyMuPDF4LLM ì‹œë„ (ë‹¤ì–‘í•œ ì˜µì…˜)
print("\n=== PyMuPDF4LLM Extraction ===")

# ì˜µì…˜ 1: ê¸°ë³¸
print("\n1. Basic extraction:")
md_text = pymupdf4llm.to_markdown(PDF_PATH)
print(f"   Length: {len(md_text)}")

# ì˜µì…˜ 2: page_chunks í™œì„±í™”
print("\n2. With page_chunks:")
md_chunks = pymupdf4llm.to_markdown(PDF_PATH, page_chunks=True)
print(f"   Chunks: {len(md_chunks) if isinstance(md_chunks, list) else 'N/A'}")
if isinstance(md_chunks, list) and md_chunks:
    print(f"   First chunk length: {len(md_chunks[0].get('text', ''))}")
    print(f"   First chunk preview: {md_chunks[0].get('text', '')[:300]}")

# ì˜µì…˜ 3: ì´ë¯¸ì§€ í¬í•¨
print("\n3. With images:")
try:
    md_with_images = pymupdf4llm.to_markdown(
        PDF_PATH,
        write_images=True,
        image_path="extracted_images",
        page_chunks=True
    )
    print(f"   Success! Chunks: {len(md_with_images) if isinstance(md_with_images, list) else 'N/A'}")
    if isinstance(md_with_images, list) and md_with_images:
        print(f"   First chunk: {md_with_images[0].get('text', '')[:300]}")
except Exception as e:
    print(f"   Error: {e}")

# ==========================
# 4ï¸âƒ£ ì¶”ì¶œëœ ì´ë¯¸ì§€ì— OCR ì ìš©
# ==========================
print("\n=== OCR on Extracted Images ===")

image_dir = "extracted_images"
if os.path.exists(image_dir):
    image_files = [f for f in os.listdir(image_dir) if f.endswith('.png')]
    print(f"Found {len(image_files)} images")

    for img_file in image_files:
        img_path = os.path.join(image_dir, img_file)
        print(f"\n[{img_file}] OCR ì‹œì‘...")

        # ì´ë¯¸ì§€ ë¡œë“œ
        img = Image.open(img_path)

        # Tesseract OCR
        ocr_text = pytesseract.image_to_string(img, lang='kor+eng', config='--psm 6')
        print(f"  í…ìŠ¤íŠ¸ ê¸¸ì´: {len(ocr_text)}")

        # ìœ„ì¹˜ ì •ë³´ í¬í•¨ OCR
        data = pytesseract.image_to_data(img, lang='kor+eng', config='--psm 6', output_type=pytesseract.Output.DICT)

        # ë¯¼ê° ì •ë³´ ì°¾ê¸°: ì¹´ë“œë²ˆí˜¸ + 8~10ìë¦¬ ëª¨ë“  ìˆ«ì
        n_boxes = len(data['text'])
        positions = []

        print(f"  ì´ {n_boxes}ê°œ í…ìŠ¤íŠ¸ ë°•ìŠ¤ ê²€ì‚¬ ì¤‘...")

        for i in range(n_boxes):
            if int(data['conf'][i]) < 30:
                continue

            text = data['text'][i].strip()
            if not text:
                continue

            text_digits = re.sub(r'[^0-9*]', '', text)

            # ì¹´ë“œë²ˆí˜¸ (15ìë¦¬ ì´ìƒ, *í¬í•¨)
            if len(text_digits) >= 15:
                x, y, w, h = data['left'][i], data['top'][i], data['width'][i], data['height'][i]
                positions.append(('ì¹´ë“œë²ˆí˜¸', x, y, w, h))
                print(f"  ğŸ” ì¹´ë“œë²ˆí˜¸: {text} (ìœ„ì¹˜: {x}, {y})")

            # 8~10ìë¦¬ ìˆ«ì (ë‚ ì§œ ì œì™¸)
            elif 8 <= len(text_digits) <= 10:
                # ë‚ ì§œ íŒ¨í„´ ì œì™¸ (YYYY-MM-DD í˜•íƒœ)
                if not re.match(r'20\d{2}[-/]\d{2}[-/]\d{2}', text):
                    x, y, w, h = data['left'][i], data['top'][i], data['width'][i], data['height'][i]
                    positions.append((f'{len(text_digits)}ìë¦¬', x, y, w, h))
                    print(f"  ğŸ” {len(text_digits)}ìë¦¬ ìˆ«ì: {text} (ìœ„ì¹˜: {x}, {y})")

        # ë¸”ëŸ¬ ì²˜ë¦¬
        if positions:
            print(f"\n  ë¸”ëŸ¬ ì²˜ë¦¬ ì‹œì‘... ({len(positions)}ê°œ ìœ„ì¹˜)")
            img_array = np.array(img)
            blurred = img_array.copy()

            for label, x, y, w, h in positions:
                padding = 10
                x1 = max(0, x - padding)
                y1 = max(0, y - padding)
                x2 = min(blurred.shape[1], x + w + padding)
                y2 = min(blurred.shape[0], y + h + padding)

                roi = blurred[y1:y2, x1:x2]
                if roi.size > 0:
                    blurred_roi = cv2.GaussianBlur(roi, (51, 51), 0)
                    blurred[y1:y2, x1:x2] = blurred_roi
                    print(f"  âœ… {label} ë¸”ëŸ¬ ì™„ë£Œ")

            # ì €ì¥
            output_path = f"blurred_pymupdf4llm_{img_file}"
            blurred_img = Image.fromarray(blurred)
            blurred_img.save(output_path)
            print(f"  ğŸ’¾ ì €ì¥: {output_path}")

        print(f"\n  === OCR í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸° ===")
        print(ocr_text[:500])
else:
    print("âš ï¸ No images extracted")
