import pymupdf4llm
import fitz
import pytesseract
import cv2
import numpy as np
from PIL import Image
import re
import os
import glob
from datetime import datetime
import uuid

FOLDER_PATH = r"C:\Users\user\Desktop\expense_cliaim"
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

# ì‘ì—… ì‹œì‘ ì‹œê°„ ê¸°ë¡
start_time = datetime.now()
timestamp = start_time.strftime("%Y%m%d%H%M%S")
job_uuid = str(uuid.uuid4())[:8]  # UUIDì˜ ì• 8ìë¦¬ë§Œ ì‚¬ìš©

# ì¶œë ¥ í´ë”ëª…: ì‘ì—…ì‹œì‘ì‹œê°„ + UUID
output_folder = f"extracted_images/{timestamp}_{job_uuid}"
os.makedirs(output_folder, exist_ok=True)


# 1. ì´ uuidëŠ” í•¨ìˆ˜ë¡œ ì„¤ì •ì‹œ parameterë¡œ ë°›ì„ ìˆ˜ ìˆê²Œ í•  ê²ƒ. ì™œëƒë©´ ì´ í´ë” ì´ë¦„ì„ ì „ ë‹¨ê³„ì—ì„œ ì•Œì•„ì•¼ ë‹¤ë¥¸ ì‘ì—…ì—ì„œ ì´ í´ë” ì§€ì •í•´ì„œ í• í…Œë‹ˆê¹Œ.
# 2. parameterë¡œ ë°›ì„ê±°ëŠ”. ì‘ì—…í´ë”ëª…, ì‘ì—…ì ì•„ì´ë””, 


print("PyMuPDF4LLM + OCR Pipeline (Batch Processing)")
print(f"Folder: {FOLDER_PATH}")
print(f"ì‘ì—… ì‹œì‘: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
print(f"ì¶œë ¥ í´ë”: {output_folder}")

# í´ë” ë‚´ ëª¨ë“  PDF íŒŒì¼ ì°¾ê¸°
pdf_files = glob.glob(os.path.join(FOLDER_PATH, "*.pdf"))
print(f"\në°œê²¬ëœ PDF íŒŒì¼: {len(pdf_files)}ê°œ")

if not pdf_files:
    print("âš ï¸ PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
    exit()

for pdf_idx, PDF_PATH in enumerate(pdf_files, 1):
    print(f"\n{'='*80}")
    print(f"[{pdf_idx}/{len(pdf_files)}] ì²˜ë¦¬ ì¤‘: {os.path.basename(PDF_PATH)}")
    print(f"{'='*80}")

    # ë¨¼ì € PyMuPDFë¡œ í…ìŠ¤íŠ¸ê°€ ìˆëŠ”ì§€ í™•ì¸
    doc = fitz.open(PDF_PATH)
    print(f"\nTotal pages: {len(doc)}")

    for page_num in range(len(doc)):
        page = doc[page_num]
        text = page.get_text()
        print(f"\nPage {page_num + 1} - Text length: {len(text)}")
        if text.strip():
            print(f"First 200 chars: {text[:200]}")
        else:
            print("âš ï¸ No text found - This is likely an image-based PDF")

    doc.close()

    # PyMuPDF4LLM ì‹œë„ (ë‹¤ì–‘í•œ ì˜µì…˜)
    print("\n=== PyMuPDF4LLM Extraction ===")

    # ì˜µì…˜ 1: ê¸°ë³¸
    print("\n1. Basic extraction:")
    md_text = pymupdf4llm.to_markdown(PDF_PATH)
    print(f"   Length: {len(md_text)}")

    # ì˜µì…˜ 2: page_chunks í™œì„±í™”
    print("\n2. With page_chunks:")
    md_chunks = pymupdf4llm.to_markdown(PDF_PATH, page_chunks=True)
    print(f"   Chunks: {len(md_chunks) if isinstance(md_chunks, list) else 'N/A'}")
    if isinstance(md_chunks, list) and md_chunks:
        print(f"   First chunk length: {len(md_chunks[0].get('text', ''))}")
        print(f"   First chunk preview: {md_chunks[0].get('text', '')[:300]}")

    # PDFë³„ ì„ì‹œ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ìƒì„±
    pdf_name = os.path.splitext(os.path.basename(PDF_PATH))[0]
    temp_image_dir = f"temp_extracted/{pdf_name}"
    os.makedirs(temp_image_dir, exist_ok=True)

    # ì˜µì…˜ 3: ì´ë¯¸ì§€ í¬í•¨
    print("\n3. With images:")
    try:
        md_with_images = pymupdf4llm.to_markdown(
            PDF_PATH,
            write_images=True,
            image_path=temp_image_dir,
            page_chunks=True
        )
        print(f"   Success! Chunks: {len(md_with_images) if isinstance(md_with_images, list) else 'N/A'}")
        if isinstance(md_with_images, list) and md_with_images:
            print(f"   First chunk: {md_with_images[0].get('text', '')[:300]}")
    except Exception as e:
        print(f"   Error: {e}")

    # ==========================
    # 4ï¸âƒ£ ì¶”ì¶œëœ ì´ë¯¸ì§€ì— OCR ì ìš©
    # ==========================
    print("\n=== OCR on Extracted Images ===")

    if os.path.exists(temp_image_dir):
        image_files = [f for f in os.listdir(temp_image_dir) if f.endswith('.png')]
        print(f"Found {len(image_files)} images")

        for img_file in image_files:
            img_path = os.path.join(temp_image_dir, img_file)
            print(f"\n[{img_file}] OCR ì‹œì‘...")

            # ì´ë¯¸ì§€ ë¡œë“œ
            img = Image.open(img_path)

            # Tesseract OCR
            ocr_text = pytesseract.image_to_string(img, lang='kor+eng', config='--psm 6')
            print(f"  í…ìŠ¤íŠ¸ ê¸¸ì´: {len(ocr_text)}")

            # ìœ„ì¹˜ ì •ë³´ í¬í•¨ OCR
            data = pytesseract.image_to_data(img, lang='kor+eng', config='--psm 6', output_type=pytesseract.Output.DICT)

            # ë¯¼ê° ì •ë³´ ì°¾ê¸°: ì¹´ë“œë²ˆí˜¸ + 8~10ìë¦¬ ëª¨ë“  ìˆ«ì
            n_boxes = len(data['text'])
            positions = []

            print(f"  ì´ {n_boxes}ê°œ í…ìŠ¤íŠ¸ ë°•ìŠ¤ ê²€ì‚¬ ì¤‘...")

            for i in range(n_boxes):
                if int(data['conf'][i]) < 30:
                    continue

                text = data['text'][i].strip()
                if not text:
                    continue

                text_digits = re.sub(r'[^0-9*]', '', text)

                # ì¹´ë“œë²ˆí˜¸ (15ìë¦¬ ì´ìƒ, *í¬í•¨)
                if len(text_digits) >= 15:
                    x, y, w, h = data['left'][i], data['top'][i], data['width'][i], data['height'][i]
                    positions.append(('ì¹´ë“œë²ˆí˜¸', x, y, w, h))
                    print(f"  ğŸ” ì¹´ë“œë²ˆí˜¸: {text} (ìœ„ì¹˜: {x}, {y})")

                # 8~10ìë¦¬ ìˆ«ì (ë‚ ì§œ ì œì™¸)
                elif 8 <= len(text_digits) <= 10:
                    # ë‚ ì§œ íŒ¨í„´ ì œì™¸ (YYYY-MM-DD í˜•íƒœ)
                    if not re.match(r'20\d{2}[-/]\d{2}[-/]\d{2}', text):
                        x, y, w, h = data['left'][i], data['top'][i], data['width'][i], data['height'][i]
                        positions.append((f'{len(text_digits)}ìë¦¬', x, y, w, h))
                        print(f"  ğŸ” {len(text_digits)}ìë¦¬ ìˆ«ì: {text} (ìœ„ì¹˜: {x}, {y})")

            # ë¸”ëŸ¬ ì²˜ë¦¬
            if positions:
                print(f"\n  ë¸”ëŸ¬ ì²˜ë¦¬ ì‹œì‘... ({len(positions)}ê°œ ìœ„ì¹˜)")
                img_array = np.array(img)
                blurred = img_array.copy()

                for label, x, y, w, h in positions:
                    padding = 10
                    x1 = max(0, x - padding)
                    y1 = max(0, y - padding)
                    x2 = min(blurred.shape[1], x + w + padding)
                    y2 = min(blurred.shape[0], y + h + padding)

                    roi = blurred[y1:y2, x1:x2]
                    if roi.size > 0:
                        blurred_roi = cv2.GaussianBlur(roi, (51, 51), 0)
                        blurred[y1:y2, x1:x2] = blurred_roi
                        print(f"  âœ… {label} ë¸”ëŸ¬ ì™„ë£Œ")

                # ì €ì¥ - íŒŒì¼ëª…: ì‘ì—…ì‹œì‘ì‹œê°„ + ì›ë³¸íŒŒì¼ëª…
                output_filename = f"{timestamp}_{pdf_name}_{img_file}"
                output_path = os.path.join(output_folder, output_filename)
                blurred_img = Image.fromarray(blurred)
                blurred_img.save(output_path)
                print(f"  ğŸ’¾ ì €ì¥: {output_path}")

            print(f"\n  === OCR í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸° ===")
            print(ocr_text[:500])
    else:
        print("âš ï¸ No images extracted")

# ì„ì‹œ í´ë” ì •ë¦¬
import shutil
if os.path.exists("temp_extracted"):
    shutil.rmtree("temp_extracted")
    print("\nğŸ—‘ï¸ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")

print(f"\n{'='*80}")
print(f"âœ… ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ! ì´ {len(pdf_files)}ê°œ PDF íŒŒì¼ ì²˜ë¦¬ë¨")
print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {output_folder}")
print(f"{'='*80}")
